{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edbd0af-dfc4-4216-9b36-79bdc604542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install tensorflow\n",
    "!pip install keras-tuner   #to decide how many dense layers are to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b91c6a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2e3e284-b312-4f27-808b-23c494326d0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d3de28b-c939-495a-b59f-3678d0d2b27a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "535d9718-f2d2-452c-a2a7-d94d5d525c66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train = np.loadtxt('train.csv', skiprows=1, delimiter=',') # add dtype=int if it shows error in colab\n",
    "test=np.loadtxt('test.csv',skiprows=1,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e7d23f-9083-4600-928f-3ad5871ffc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[0]  #1st row- includes train label+train image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e32a9eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train[:,0] # for last column\n",
    "train_images = train[:,1 :] # for all but last column\n",
    "test_images = test[:,:] # for last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "307c61b4-6897-4624-947c-f51cd8462034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785) (28000, 784)\n",
      "785\n"
     ]
    }
   ],
   "source": [
    "print(train.shape,test.shape)\n",
    "print(len(train[13190]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bc00573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 4., 0., 0., 7., 3., 5., 3.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0:10]  #print first 10 train labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a5a1cf90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: %%time is a cell magic, but the cell body is empty. Did you mean the line magic %time (single %)?\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# count={}\n",
    "# for i in train_labels:\n",
    "# #     i=str(i)\n",
    "#     if i in count:\n",
    "#         count[i]+=1\n",
    "#     else:\n",
    "#         count[i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5659ecbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "785"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape\n",
    "len(train[22946])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7c398ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=train_images.reshape(len(train_images),28,28,1) #42000 rows/dataset, each row having a array of 28*28 i.e 28 rows and 28 columns in gray scale-1, 3 for colour.   Also try to see for (len(train_images),28,14,2) \n",
    "test_images=test_images.reshape(len(test_images),28,28,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04e467c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,5))\n",
    "# for i in range(20):\n",
    "\n",
    "plt.imshow(train_images[0],cmap='gray')\n",
    "plt.title('y={}'.format(train_labels[0]))\n",
    "plt.axis('off')\n",
    "    \n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2190fe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=train_images/255.0  #feature scaling b/w 0-1 to train the images easily\n",
    "test_images=test_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af0dfa38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1744dd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a5719c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model= keras.Sequential([\n",
    "                    keras.layers.Conv2D(filters=hp.Int('conv_1_filter',min_value=32,max_value=128,step=16), #32 filters/kernels\n",
    "                                         kernel_size=hp.Choice('conv_1_kernel',values=[3,5]),\n",
    "                                         activation='relu',\n",
    "                                         input_shape=(28,28,1)\n",
    "                                         ),\n",
    "\n",
    "                    #adding second convolutional layer bec it helps in finding features in pictures in a better way/ more precise manner\n",
    "                    keras.layers.Conv2D(\n",
    "                        filters=hp.Int('conv_2_filter',min_value=32,max_value=128,step=16),\n",
    "                        kernel_size=hp.Choice('conv_2_kernel',values=[3,5]),\n",
    "                        activation='relu'\n",
    "                    ),\n",
    "#                     keras.layers.Conv2D(\n",
    "#                         filters=hp.Int('conv_3_filter',min_value=32,max_value=128,step=16),\n",
    "#                         kernel_size=hp.Choice('conv_3_kernel',values=[3,5]),\n",
    "#                         activation='relu'\n",
    "#                     ),\n",
    "                    keras.layers.Flatten(), #flatenning all the values of multiple small matrices after max pooling into a single vector column whihc acts as an input layer for ANN then\n",
    "                    keras.layers.Dense(\n",
    "                        units=hp.Int('dense_1_units',min_value=32,max_value=128,step=16),\n",
    "                        activation='relu'\n",
    "                    ),\n",
    "                    keras.layers.Dense(10,activation='softmax')\n",
    "                    ])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate',values=[1e-2,1e-3])),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54409760",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k8/lsx1j9kj7p55q4qrhnfpz11r0000gn/T/ipykernel_8145/212572501.py:1: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner import RandomSearch  #to check which hyperparametrs are good for our model\n"
     ]
    }
   ],
   "source": [
    "from kerastuner import RandomSearch  #to check which hyperparametrs are good for our model\n",
    "# from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from kerastuner.engine.hyperparameters import HyperParameter\n",
    "# from kerastuner.engine.hyperparameters import Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69bd7d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from output/digit recognition/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner_search= RandomSearch(build_model,objective='val_accuracy', max_trials=5,directory='output', project_name='digit recognition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70248b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 Complete [00h 03m 45s]\n",
      "val_accuracy: 0.9850000143051147\n",
      "\n",
      "Best val_accuracy So Far: 0.9892857074737549\n",
      "Total elapsed time: 00h 03m 45s\n"
     ]
    }
   ],
   "source": [
    "tuner_search.search(train_images,train_labels,epochs=3,validation_split=0.1) #default value of epochs=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7661280",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n"
     ]
    }
   ],
   "source": [
    "model=tuner_search.get_best_models(num_models=1)[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a8a5270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 24, 24, 64)        1664      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 22, 22, 32)        18464     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 15488)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 112)               1734768   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1756026 (6.70 MB)\n",
      "Trainable params: 1756026 (6.70 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78b67483",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output shape: (batch size, height, weight, depth). Here it is convo2d layer as (none,24,24,64). Since there are no batches we now in advance so none, else when we change the batch size, it will change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f8d98f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/12\n",
      "1182/1182 [==============================] - 25s 21ms/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.0611 - val_accuracy: 0.9876\n",
      "Epoch 11/12\n",
      "1182/1182 [==============================] - 24s 21ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0634 - val_accuracy: 0.9869\n",
      "Epoch 12/12\n",
      "1182/1182 [==============================] - 25s 21ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.0833 - val_accuracy: 0.9876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2dcea2250>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images,train_labels,epochs=12,validation_split=0.1, initial_epoch=9) \n",
    "#to check for 10 epochs, when first 3 epochs we have already done. Epoch at which to start training (useful for resuming a previous training run).\n",
    "#mostly useful when you have trained your model for some epochs, say 10, and then saved it and now you want to load it and resume the training for another 10 epochs without disrupting the state of epoch-dependent objects (e.g. optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c8f7e8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875/875 [==============================] - 4s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0b2d2542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,5))\n",
    "# for i in range(20):\n",
    "\n",
    "plt.imshow(test_images[0],cmap='gray')\n",
    "plt.title('y={}'.format(np.argmax(result[0])))\n",
    "plt.axis('off')\n",
    "    \n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a0e450f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 10)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8bb9c1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1313/1313 [==============================] - 6s 5ms/step\n",
      "1 1.0\n",
      "0 0.0\n",
      "1 1.0\n",
      "4 4.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "7 7.0\n",
      "3 3.0\n",
      "5 5.0\n",
      "3 3.0\n",
      "8 8.0\n",
      "9 9.0\n",
      "1 1.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "1 1.0\n",
      "2 2.0\n",
      "0 0.0\n",
      "7 7.0\n",
      "5 5.0\n",
      "8 8.0\n",
      "6 6.0\n",
      "2 2.0\n",
      "0 0.0\n",
      "2 2.0\n",
      "3 3.0\n",
      "6 6.0\n",
      "9 9.0\n",
      "9 9.0\n",
      "7 7.0\n"
     ]
    }
   ],
   "source": [
    "result2=model.predict(train_images)\n",
    "for i in range(30):\n",
    "    print(np.argmax(result2[i]),train_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eb9223",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
